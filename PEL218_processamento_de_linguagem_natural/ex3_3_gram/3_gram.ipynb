{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEL218 - Atividade 3\n",
    "Processamento de Linguagem Narual (Prof. Guilherme Wachs)\n",
    "\n",
    "Claudio Aparecido Borges Junior (RA 120122-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atividade\n",
    "Implementar um modelo de linguagem 3-Grama com interpolação\n",
    "* Baixa o arquivo CHAVEFolha.zip do moodle;\n",
    "* A base de treinamento está na pasta **folha95**;\n",
    "* Texto está nas tags <TEXT>;\n",
    "* Tokenizar por palavras, transformar em minúsculo, retirar pontuação;\n",
    "* Criar modelo 3-grama;\n",
    "* Usar a base de teste **folha94** para medir a perplexidade por <TEXT>\n",
    "* Fazer um relatório sobre os resultados:\n",
    "    * Análise da base de treinamento (número de palavras, tamanho do vocabulário)\n",
    "    * Extrato de maior perplexidade, menor e a distribuição de perplexidade;\n",
    "    * Discutir os resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolução\n",
    "Foi escolhida a linguagem *Python* versão 3.8.5. Os arquivos folha95 foram usados para treinamento e os folha94 para teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folha95_path = 'CHAVEFolha/folha95/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folha95_files = os.listdir(folha95_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções para ler, preparar e tokenizar os documentos:\n",
    "\n",
    "`read_lines:` lê cada linha do documentos na forma de *generator*\n",
    "\n",
    "`prepare_3gram:` prepara uma linha para 3-gramas adicionando \\<s\\> e \\</s\\>\n",
    "\n",
    "`tokeniz:` tokenização de palavras na forma de *generator* e substitui palavras OOV para \\<unk\\> se um vocabulario estiver presente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lines(root_path, file_paths):\n",
    "    for file_path in file_paths:\n",
    "        with open(os.path.join(os.getcwd(), root_path, file_path), 'r', encoding='iso-8859-1') as f:\n",
    "            it = re.finditer(r'<TEXT>(.+?)</TEXT>', f.read(), re.MULTILINE | re.DOTALL)\n",
    "            for match in it:\n",
    "                lines = match.groups(0)[0].splitlines()\n",
    "                for line in lines:\n",
    "                    if line:\n",
    "                        yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_3gram(line):\n",
    "    return '<s> <s> ' + line + ' </s> </s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string, vocabulary=None):\n",
    "    it = re.finditer(\"<s>|<\\/s>|[-a-zA-Z\\xc0-\\xff]+\", string, flags=re.MULTILINE | re.DOTALL)\n",
    "    for word in it:\n",
    "        w = word.group(0).lower()\n",
    "        if vocabulary:\n",
    "            if w not in vocabulary and w != '<s>' and w != '</s>':\n",
    "                w = '<unk>'\n",
    "        yield w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constroi vocabulário usando a base de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_pre = collections.Counter()\n",
    "\n",
    "for line in read_lines(folha95_path, folha95_files):\n",
    "    vocabulary_pre.update(tokenize(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleciona palavras que apareceram apenas 1 vez do conjunto de treinamento e as substituem para \\<unk\\>. Desse modo é possível treinar casos de OOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palavras com uma ocorrência menor or igual a `oov_train_threshold` são transformadas em <unk>,\n",
    "# desse modo podemos treinar <unk> na base de treinamento simulando um vocabulário definido\n",
    "oov_train_threshold = 1\n",
    "oov_train = [w for w, n in vocabulary_pre.items() if n <= oov_train_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = copy.deepcopy(vocabulary_pre)\n",
    "for w in oov_train:\n",
    "    c = vocabulary_pre[w]\n",
    "    del vocabulary[w]\n",
    "    vocabulary['<unk>'] += c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estatísticas da base de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de palavras: 17982871\n",
      "Tamanho do vocabulário: 210901\n",
      "Relação do vocabulário e da quantidade de palavras: 1.17%\n",
      "Palavra \"de\" ocorreu 894061 vezes\n",
      "Palavra \"a\" ocorreu 637392 vezes\n",
      "Palavra \"o\" ocorreu 605855 vezes\n",
      "Palavra \"e\" ocorreu 428649 vezes\n",
      "Palavra \"que\" ocorreu 425298 vezes\n",
      "Palavra \"do\" ocorreu 357115 vezes\n",
      "Palavra \"da\" ocorreu 315598 vezes\n",
      "Palavra \"em\" ocorreu 245729 vezes\n",
      "Palavra \"para\" ocorreu 205622 vezes\n",
      "Palavra \"é\" ocorreu 172255 vezes\n"
     ]
    }
   ],
   "source": [
    "n_words_pre = sum(vocabulary_pre.values())\n",
    "n_voc_pre = len(vocabulary_pre)\n",
    "\n",
    "print('Número de palavras:', n_words_pre)\n",
    "print('Tamanho do vocabulário:', n_voc_pre)\n",
    "print('Relação do vocabulário e da quantidade de palavras:',\n",
    "      '{0:.2f}'.format(n_voc_pre / n_words_pre * 100) + '%' )\n",
    "for word, n in vocabulary.most_common(10):\n",
    "    print('Palavra \"' + word + '\" ocorreu ' + str(n) + ' vezes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estatísticas da base após a substituição para \\<unk\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de palavras: 17982871\n",
      "Tamanho do vocabulário: 127800\n",
      "Quantidade de palavras consideradas <unk>: 83102\n",
      "Relação do vocabulário e da quantidade de palavras: 0.71%\n"
     ]
    }
   ],
   "source": [
    "n_words = sum(vocabulary.values())\n",
    "n_voc = len(vocabulary)\n",
    "\n",
    "print('Número de palavras:', n_words)\n",
    "print('Tamanho do vocabulário:', n_voc)\n",
    "print('Quantidade de palavras consideradas <unk>:', len(oov_train))\n",
    "print('Relação do vocabulário e da quantidade de palavras:',\n",
    "      '{0:.2f}'.format(n_voc / n_words * 100) + '%' )\n",
    "\n",
    "assert n_voc + len(oov_train) - 1 == n_voc_pre, 'Fail on vocabulary normalization'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constrói a matriz de frequência para 3-gram, 2-gram e 1-gram\n",
    "\n",
    "São necessárias as 3 variações para poder utilizar o método da interpolação quando a probabilidade for 0\n",
    "\n",
    "`ngrams:` retorna um generator de tamanho do ngrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(tokens, n):\n",
    "    t = list(tokens)\n",
    "    for i in range(len(t) -n +1):\n",
    "        yield t[i:i+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = collections.defaultdict(int)\n",
    "\n",
    "for line in read_lines(folha95_path, folha95_files):\n",
    "    line_marked = prepare_3gram(line)\n",
    "\n",
    "    for i in range(1, 4):\n",
    "        for w in generate_ngrams(tokenize(line_marked, vocabulary), i):\n",
    "            s = ' '.join(w)\n",
    "            ngrams[s] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcula a perplexidade da base de testes\n",
    "\n",
    "As palavras que não estão presentes no vocabulário de treinamento são substituídas para \\<unk\\> e as probabilidades são interpoladas entre 3, 2 e 1 grama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "folha94_path = 'CHAVEFolha/folha94/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "folha94_files = os.listdir(folha94_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define os hiperparâmetros lambda utilizados na interpolação\n",
    "lambda_n3 = 0.5\n",
    "lambda_n2 = 0.3\n",
    "lambda_n1 = 0.2\n",
    "\n",
    "p_line = []\n",
    "for line in read_lines(folha94_path, folha94_files):\n",
    "    line_marked = prepare_3gram(line)\n",
    "    \n",
    "    p = []\n",
    "    for w in generate_ngrams(tokenize(line_marked, vocabulary), 3):\n",
    "        n3 = ' '.join(w)\n",
    "        n2 = ' '.join(w[1:3])\n",
    "        n1 = w[2]\n",
    "        p3 = ngrams[n3]/ngrams[n2] if ngrams[n3] else 0\n",
    "        p2 = ngrams[n2]/ngrams[n1] if ngrams[n2] else 0\n",
    "        p1 = ngrams[n1]/n_words if ngrams[n1] else 0\n",
    "        assert p3 + p2 + p1 > 0, '{}, {}, {}, {}'.format(n3, p3, p2, p1)\n",
    "        \n",
    "        p.append(lambda_n3 * p3 + lambda_n2 * p2 + lambda_n1 * p1)\n",
    "        \n",
    "    p_line.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula a perplexidade de cada linha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(ps):\n",
    "    prod = 1;\n",
    "    for p in ps:\n",
    "        prod *= 1/p\n",
    "    return prod ** (1/len(ps))\n",
    "\n",
    "pps = []\n",
    "for p in p_line:\n",
    "    pp = perplexity(p)\n",
    "    pps.append(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estatísticas da perplexidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As 10 perplexidades que mais aparecem\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2.1165361549547326, 11141),\n",
       " (3.4013969896604017, 3413),\n",
       " (2.1686565992586515, 3043),\n",
       " (2.433739888981176, 2326),\n",
       " (inf, 2228),\n",
       " (3.9083881205362907, 1910),\n",
       " (2.575215402113554, 1767),\n",
       " (2.4216718998197733, 1512),\n",
       " (4.101446267538539, 866),\n",
       " (2.4666432938746645, 824)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_counter = collections.Counter(pps)\n",
    "print(\"As 10 perplexidades que mais aparecem\")\n",
    "pp_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupa a paerpexidade em grupos\n",
    "bins = {i:0 for i in range(10000)}\n",
    "\n",
    "for pp in pps:\n",
    "    for b in bins:\n",
    "        if pp <= b:\n",
    "            bins[b] += 1\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de frases na base de teste 558346\n",
      "Maior perplexidade: inf\n",
      "Menor perplexidade: 1.9588769365320562\n",
      "Distribuição de perplexidade: [(3, 37707), (4, 19091), (5, 7957), (6, 6988), (7, 5767), (10, 5039), (8, 5008), (9, 4150), (36, 3845), (31, 3760), (30, 3738), (32, 3736), (40, 3703), (29, 3683), (38, 3676), (37, 3662), (35, 3661), (34, 3653), (39, 3636), (44, 3617)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de frases na base de teste\", len(pps))\n",
    "print(\"Maior perplexidade:\", max(pps))\n",
    "print(\"Menor perplexidade:\", min(pps))\n",
    "print(\"Distribuição de perplexidade:\", collections.Counter(bins).most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussão dos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A quatidade de palavras únicas, chamada de vocabulário, da base de treinamento é de 210.901 palavras. Essa mesma base possui um total de 17.982.871 palavras, contabilizando portanto um vocabulário de extensão de 1.17%. Porém, para que fosse possível treinar a existência de palavras desconhecidas, isto é, palavras nunca vistas antes, todas os termos com ocorrência unitária foram substituidos para `<unk>`, estabelecendo assim um dicionário fechado implicitamente. Tais léxicos portanto formaram um outro conjunto com extensão de 127.800 ocorrências únicas ou 0.71%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As palavras que ocorreram com maior ocorrência na base de treinamento foram artigos, preposições, conjunções, alguns poucos substantivos como presidente, folha, Brasil, país, são, paulo, rio, e também o marcador `<unk>`. Como o generero da base de treinamento é jornalístico, nomes de Estados (São Paulo e Rio de Janeiro) são notoriamente utilizados, além de termos políticos (Presidente), nomes de países (Brasil) e do próprio jornal (Folha)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base de dados `folha94` foi utilizada para availiar a perplexidade e assim julgar a qualidade do modelo n-grama. Essa medida é o inverso da probabilidade de uma sentença ocorrer normalizada pelo número de palavras, sendo que, minimizar a perplexidade é o mesmo que aumentar a probabilidade do conjundo de teste. A perplexidade foi calculada por sentença, desse modo cada frase possui uma perplexidade distinta. A distribuição de probabilidade de perplexidade pode ser vista abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(bins.keys(), bins.values())\n",
    "plt.xlim(-1, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram identificadas 64.848 sentenças com perplexidades menores do que 5, ou seja, 11,61% das sentençãs possuem uma perplexidade 20 vezes menor se comparada com a mesma medida exibida por Jurafsky, 2019 em seu ensaio de tri-frama com mais do que 1.5 milhões de termos do WSJ. O intervalo de perplexidade entre 2 e 3 possui a maior quantidade de linhas, totalizando 37.707 ou 6,75% do conjunto de testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando o resultado obtido por Jurafksy, 2019 em seu ensaio com os dados do WSJ que foi encontrado uma perplexidade de 109 para tri-grama, o presente documento encontrou 373.552 linhas com perplexidade menor ou igual a 109, ou seja 66,90% dos exemplos de testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A menor perplexidade encontrada foi de 1,96 enquanto a maior perplexidade foi inifinita. Isso indica que houveram casos onde a probabilidade de ocorrência de uma sentença com base nos n-gramas treinados com a base de treinamento foi tão pequena que causaram estouro do limite de dados pelo Python. Esse evento ocorreu tanto utilizando as probabilidades em seu formado normal quanto utilizando base logarítmica, isto é houveram casos onde a probabilidade logarítmica foi menor do que -700. Houveram casos em que a probabilidade logarítimica foi menor do que -5443. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
